{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yahoo regression of 國泰金.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "RJGCxOSytYKO",
        "gFh9ne3FZ-On",
        "Ng0oCkzKG6WV"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jackychia/AIforCE/blob/master/yahoo_regression_of_%E5%9C%8B%E6%B3%B0%E9%87%91.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOqS8eI6uBg-",
        "colab_type": "text"
      },
      "source": [
        "# 交通土木108下_人工智慧\n",
        "\n",
        "---\n",
        "組員：\n",
        "\n",
        "\n",
        "1.   黃柏瑜 0511328\n",
        "2.   賈鎮宇 0511318\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EIdT9iu_Z4Rb"
      },
      "source": [
        "# Basic regression : Predict 國泰金"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJGCxOSytYKO",
        "colab_type": "text"
      },
      "source": [
        "##  < setup background"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "moB4tpEHxKB3",
        "colab": {}
      },
      "source": [
        "!pip install seaborn\n",
        "!pip install git+https://github.com/tensorflow/docs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1rRo8oNqZ-Rj",
        "colab": {}
      },
      "source": [
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F_72b0LCNbjx"
      },
      "source": [
        "## < dataset Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gFh9ne3FZ-On"
      },
      "source": [
        "### < < Get the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nslsRLh7Zss4"
      },
      "source": [
        "Import it using pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0Acvslx3WMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import檔案\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" to id:fn  (with length {length} bytes)'.format(name=fn, length=len(uploaded[fn])))\n",
        "#column_names = ['open_pre','open','high','low','close','adj_close','volume']\n",
        "dataset = pd.read_csv(fn,na_values = \"0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4WribvI3WEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng0oCkzKG6WV",
        "colab_type": "text"
      },
      "source": [
        "### Make prediction columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h-9JoblHlFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['Open_pre'] = dataset['Open'].shift(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3MWuJTKEDM-f"
      },
      "source": [
        "### < <  Clean the data\n",
        "\n",
        "The dataset contains a few unknown values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JEJHhN65a2VV",
        "colab": {}
      },
      "source": [
        "dataset.isna().sum()\n",
        "dataset = dataset.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRwhKJl1BAJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mRklxK5s388r"
      },
      "source": [
        "### < < Normalize the data\n",
        "\n",
        "Look again at the `train_stats` block above and note how different the ranges of each feature are."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q8h3Y2XhOpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def norm(x):\n",
        "  A = x.pop('Date')  #從x當中drop out資料Date,並傳給A\n",
        "  x = (x - dataset.min()) / (dataset.max() - dataset.min())\n",
        "  x = x.transpose()\n",
        "  x = x.append(A)\n",
        "  x = x.transpose()\n",
        "  return x\n",
        "\n",
        "\n",
        "normed_dataset = norm(dataset)\n",
        "#dataset=x dataset被drop掉Date的資料"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc5dQDVriV5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normed_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BuiClDk45eS4"
      },
      "source": [
        "This normalized data is what we will use to train the model.\n",
        "\n",
        "注意：未來輸入其他資料也需要normalize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Cuym4yvk76vU"
      },
      "source": [
        "### < < Split the data into train and test\n",
        "\n",
        "Now split the dataset into a training set and a test set.\n",
        "\n",
        "We will use the test set in the final evaluation of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qn-IGhUE7_1H",
        "colab": {}
      },
      "source": [
        "# `random_state` for reproducibility\n",
        "\n",
        "normed_train_dataset = normed_dataset.sample(frac=0.8,random_state=2)\n",
        "normed_test_dataset = normed_dataset.drop(normed_train_dataset.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6Qy4BvuQRoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normed_train_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZDE31MrQTet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normed_test_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J4ubs136WLNp"
      },
      "source": [
        "### < < Inspect the data\n",
        "\n",
        "Have a quick look at the joint distribution of a all pairs of columns from the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oRKO_x8gWKv-",
        "colab": {}
      },
      "source": [
        "sns.pairplot(normed_train_dataset[[\"Open_pre\",\"Open\",\"High\",\"Low\",\"Close\",\"Adj Close\",\"Volume\"]], diag_kind=\"kde\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gavKO_6DWRMP"
      },
      "source": [
        "Also look at the overall statistics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P16VKDP6uOZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yi2FzC3T21jR",
        "colab": {}
      },
      "source": [
        "B=dataset\n",
        "normed_train_stats_B = B.describe()\n",
        "normed_train_stats_B = normed_train_stats_B.transpose()\n",
        "normed_train_stats_B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Db7Auq1yXUvh"
      },
      "source": [
        "### < < Split features from labels\n",
        "\n",
        "Separate the target value, or \"label\", from the features. \n",
        "\n",
        "This label is the value that you will train the model to predict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t2sluJdCW7jN",
        "colab": {}
      },
      "source": [
        "normed_train_labels = normed_train_dataset.pop('Open_pre')  #將Open_pre預測值開盤從normed_train_dataset中提出,並提給normed_train_labels\n",
        "normed_test_labels = normed_test_dataset.pop('Open_pre')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD5mWLRLDoPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normed_train_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgVVU7-qDuF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normed_test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SmjdzxKzEu1-"
      },
      "source": [
        "## < The model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6SWtkIjhrZwa"
      },
      "source": [
        "### < < Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qWTPljFuzFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_windows(df, ref_day=5, predict_day=1):\n",
        "    normed_train_dataset, normed_train_labels = [], []\n",
        "    for i in range(df.shape[0]-predict_day-ref_day):\n",
        "        X_train_labels.append(np.array(df.iloc[i:i+ref_day,:-1]))\n",
        "        Y_train.append(np.array(df.iloc[i+ref_day:i+ref_day+predict_day][\"open_pre\"]))\n",
        "    return np.array(normed_train_dataset), np.array(normed_train_labels)\n",
        "\n",
        "def build_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.LSTM(256, input_shape=(shape[1], shape[2]), return_sequences=True))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LSTM(256, return_sequences=True))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.TimeDistributed(Dense(1)))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(5,activation='linear'))\n",
        "    model.add(layers.Dense(1,activation='linear'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c26juK7ZG8j-",
        "colab": {}
      },
      "source": [
        "#def build_model():\n",
        "#  model = keras.Sequential()\n",
        "#  model.add(layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]))\n",
        "#  model.add(layers.BatchNormalization())\n",
        "#  model.add(layers.Dense(64, activation='relu'))\n",
        "#  model.add(layers.BatchNormalization())\n",
        "#  model.add(layers.Dense(1))\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cGbPb-PHGbhs",
        "colab": {}
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sj49Og4YGULr"
      },
      "source": [
        "### < < Inspect the model\n",
        "\n",
        "Use the `.summary` method to print a simple description of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ReAD0n6MsFK-",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vt6W50qGsJAL"
      },
      "source": [
        "Now try out the model. Take a batch of `10` examples from the training data and call `model.predict` on it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-d-gBaVtGTSC",
        "colab": {}
      },
      "source": [
        "example_batch = normed_train_data[:10]\n",
        "example_result = model.predict(example_batch)\n",
        "example_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QlM8KrSOsaYo"
      },
      "source": [
        "It seems to be working, and it produces a result of the expected shape and type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0-qWCsh6DlyH"
      },
      "source": [
        "### < < Train the model\n",
        "\n",
        "Train the model for 1000 epochs, and record the training and validation accuracy in the `history` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sD7qHCmNIOY0",
        "colab": {}
      },
      "source": [
        "EPOCHS = 1000\n",
        "Batch_size = 32\n",
        "batch_size=eval(input('The batch_size (default= 32):'))\n",
        "epochs=eval(input('Epochs (default 1000):' ))\n",
        "\n",
        "history = model.fit(\n",
        "    normed_train_data, train_labels,\n",
        "    batch_size=Batch_size,epochs=EPOCHS,\n",
        "    validation_split = 0.1, verbose=0,\n",
        "    callbacks=[tfdocs.modeling.EpochDots()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tQm3pc0FYPQB"
      },
      "source": [
        "Visualize the model's training progress using the stats stored in the `history` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4Xj91b-dymEy",
        "colab": {}
      },
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "czYtZS9A6D-X",
        "colab": {}
      },
      "source": [
        "plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nMCWKskbUTvG",
        "colab": {}
      },
      "source": [
        "plotter.plot({'Basic': history}, metric = \"mae\")\n",
        "plt.ylim([0, 10])\n",
        "plt.ylabel('MAE [MPG]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N9u74b1tXMd9",
        "colab": {}
      },
      "source": [
        "plotter.plot({'Basic': history}, metric = \"mse\")\n",
        "plt.ylim([0, 20])\n",
        "plt.ylabel('MSE [MPG^2]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AqsuANc11FYv"
      },
      "source": [
        "This graph shows little improvement, or even degradation in the validation error after about 100 epochs. Let's update the `model.fit` call to automatically stop training when the validation score doesn't improve. We'll use an *EarlyStopping callback* that tests a training condition for  every epoch. If a set amount of epochs elapses without showing improvement, then automatically stop the training.\n",
        "\n",
        "You can learn more about this callback [here](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fdMZuhUgzMZ4",
        "colab": {}
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "# The patience parameter is the amount of epochs to check for improvement\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "early_history = model.fit(normed_train_data, train_labels, \n",
        "                    epochs=EPOCHS, validation_split = 0.2, verbose=0, \n",
        "                    callbacks=[early_stop, tfdocs.modeling.EpochDots()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LcopvQh3X-kX",
        "colab": {}
      },
      "source": [
        "plotter.plot({'Early Stopping': early_history}, metric = \"mae\")\n",
        "plt.ylim([0, 10])\n",
        "plt.ylabel('MAE [MPG]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3St8-DmrX8P4"
      },
      "source": [
        "The graph shows that on the validation set, the average error is usually around +/- 2 MPG. Is this good? We'll leave that decision up to you.\n",
        "\n",
        "Let's see how well the model generalizes by using the **test** set, which we did not use when training the model.  This tells us how well we can expect the model to predict when we use it in the real world."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jl_yNr5n1kms",
        "colab": {}
      },
      "source": [
        "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ft603OzXuEZC"
      },
      "source": [
        "### < < Make predictions\n",
        "\n",
        "Finally, predict MPG values using data in the testing set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6FvDPi7qhNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Number of weights after calling the model:\", model.weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xe7RXH3N3CWU",
        "colab": {}
      },
      "source": [
        "test_predictions = model.predict(normed_test_data).flatten()\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values [MPG]')\n",
        "plt.ylabel('Predictions [MPG]')\n",
        "lims = [32, 47]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "19wyogbOSU5t"
      },
      "source": [
        "It looks like our model predicts reasonably well. Let's take a look at the error distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKhdvb7XO5ZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uploaded = files.upload()\n",
        "for single_test in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" to id:single_test  (with length {length} bytes)'.format(name=single_test, length=len(uploaded[single_test])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smAEWZdGQcp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "column_names1 = ['open','high','low','close','adj_close','volume']\n",
        "X_test = pd.read_csv(single_test,names=column_names1,na_values = \"0\")\n",
        "X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYtulBJOKmDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test=norm(X_test)\n",
        "X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzBITpLgFoG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f-OHX4DiXd8x",
        "colab": {}
      },
      "source": [
        "error = test_predictions - test_labels\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Prediction Error [MPG]\")\n",
        "_ = plt.ylabel(\"Count\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m0CB5tBjSU5w"
      },
      "source": [
        "It's not quite gaussian, but we might expect that because the number of samples is very small."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vgGQuV-yqYZH"
      },
      "source": [
        "## < Conclusion\n",
        "\n",
        "This notebook introduced a few techniques to handle a regression problem.\n",
        "\n",
        "* Mean Squared Error (MSE) is a common loss function used for regression problems (different loss functions are used for classification problems).\n",
        "* Similarly, evaluation metrics used for regression differ from classification. A common regression metric is Mean Absolute Error (MAE).\n",
        "* When numeric input data features have values with different ranges, each feature should be scaled independently to the same range.\n",
        "* If there is not much training data, one technique is to prefer a small network with few hidden layers to avoid overfitting.\n",
        "* Early stopping is a useful technique to prevent overfitting."
      ]
    }
  ]
}